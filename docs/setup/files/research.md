### Objective
Ensure that any user-generated media (images, audio, music, video) created inside the WebContainer desktop/apps persists beyond local browser storage, automatically, and without requiring perâ€‘app code changes when possible.

### Current state (what exists today)
- **WebContainer boot and persistence**: The desktop runs inside a WebContainer (served via a Vite dev server in an iframe). Initial files are mounted from a binary snapshot; the userâ€™s changes are persisted locally to IndexedDB via a VFS snapshot.
  - Snapshot server route and client getter:
```1:17:src/utils/webcontainer-snapshot.ts
// Auto-generated by scripts/generate-webcontainer-snapshot.mjs
import { readFileSync } from 'node:fs';
import path from 'node:path';

/**
 * Get the binary WebContainer snapshot
 * This provides faster mounting than the tree-based approach
 */
export function getSnapshot(): Uint8Array {
  const snapshotPath = path.join(process.cwd(), 'src', 'data', 'webcontainer-snapshot.bin');
  return readFileSync(snapshotPath);
}
```

- **VFS local persistence only**: Changes are saved to IndexedDB on the host for quick restore, but not remotely.
```180:232:src/utils/vfs-persistence.ts
export function enqueuePersist(instance: WebContainerAPI) {
  // ... debounced idb persistence
}
export async function restoreFromPersistence(instance: WebContainerAPI): Promise<boolean> {
  // ... restore files from IndexedDB
}
```

- **AI calls from apps**: Apps call AI via `templates/webcontainer/src/ai/index.ts`, which posts `AI_REQUEST` to the top window; the host responds with provider results via `/api/ai/fal` or `/api/ai/eleven`.
```8:29:templates/webcontainer/src/ai/index.ts
export async function aiRequest(provider: AIProvider, model: string, input: any): Promise<any> {
  const id = generateRequestId();
  return new Promise((resolve, reject) => {
    // ...
    const payload = { type: 'AI_REQUEST', id, provider, model, input } as const;
    window.top?.postMessage(payload, '*');
    // ...
  });
}
```

- **Host bridge handles AI_REQUEST**: The WebContainer host component proxies requests to server routes and replies to the iframe with the provider JSON result.
```414:432:src/components/WebContainer.tsx
if (event.data && event.data.type === 'AI_REQUEST') {
  const { id, provider, model, input } = event.data as any;
  const srcWin = (event.source as Window | null);
  const reply = (payload: any) => { try { srcWin?.postMessage(payload, event.origin); } catch {} };
  try {
    if (provider === 'fal') {
      const res = await fetch('/api/ai/fal', { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify({ model, input }) });
      if (!res.ok) { reply({ type: 'AI_RESPONSE', id, ok: false, error: await res.text() }); return; }
      reply({ type: 'AI_RESPONSE', id, ok: true, result: await res.json() });
    } else if (provider === 'eleven') {
      const res = await fetch('/api/ai/eleven', { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(input || {}) });
      if (!res.ok) { reply({ type: 'AI_RESPONSE', id, ok: false, error: await res.text() }); return; }
      reply({ type: 'AI_RESPONSE', id, ok: true, result: await res.json() });
    }
  } catch (e: any) {
    reply({ type: 'AI_RESPONSE', id, ok: false, error: e?.message || 'Request failed' });
  }
  return;
}
```

- **AI agentâ€™s FS writes (tools)**: When the agent edits/creates files, it ultimately calls `web_fs_write` which uses `WebContainerProvider.writeFile`. There is no remote persistence hook per media extension.
```184:195:src/components/AIAgentBar.tsx
case 'web_fs_write': {
  const { path, content, createDirs = true } = tc.input as { path: string; content: string; createDirs?: boolean };
  const sizeKB = (new TextEncoder().encode(content).length / 1024).toFixed(1);
  console.log(`ðŸ”§ [Agent] web_fs_write: ${path} (${sizeKB}KB)`);
  if (createDirs) {
    const dir = path.split('/').slice(0, -1).join('/') || '.';
    await fnsRef.current.mkdir(dir, true);
  }
  await fnsRef.current.writeFile(path, content);
  addToolResult({ tool: 'web_fs_write', toolCallId: tc.toolCallId, output: { ok: true, path, size: `${sizeKB}KB` } });
  break;
}
```

### Gap vs requirement
- Media created inside apps (image generation, audio composition, video) is not automatically persisted to a remote store; it only lives in:
  - The providerâ€™s returned link (often expiring), or
  - The in-memory/app state and the local IndexedDB VFS snapshot (not durable across devices).

### Design goals
- **Automatic capture** of media produced by AI providers without modifying each app.
- **Durable storage** using a remote object store (R2/S3), with URLs returned to apps.
- **Backward compatible** with existing app contracts.
- **Providerâ€‘agnostic**, but allow providerâ€‘specific adapters for better extraction of assets.

### Proposed architecture (platformâ€‘level hooks, no perâ€‘app changes)
- **Hook point A â€“ AI bridge (best default)**
  - Extend the `AI_REQUEST` handler in `src/components/WebContainer.tsx` to:
    1) Call the provider proxy as today.
    2) Inspect the JSON result for media assets.
       - Images: common fields like `image`, `images[]`, `url`, `output[]`, `output[0].url`, etc.
       - Audio: ElevenLabs returns `{ contentType, audioBase64 }`.
       - Video: URLs or base64 blobs in provider result.
    3) Persist detected assets serverâ€‘side via a new `POST /api/media/ingest` route (described below).
    4) Replace original URLs/base64 in the response with **persisted URLs**, and include a `persistedAssets` map for transparency.
    5) Reply to the app with this augmented result. Apps keep using the `ai` helpers; no code changes per app.

- **Hook point B â€“ Agent file writes (complementary)**
  - Extend the `web_fs_write` branch in `AIAgentBar.tsx` (or `WebContainerProvider.writeFile`) to detect media file extensions (`.png`, `.jpg`, `.jpeg`, `.webp`, `.gif`, `.mp3`, `.wav`, `.m4a`, `.aac`, `.mp4`, `.webm`, etc.).
  - When media is written, asynchronously upload the bytes to remote storage via `POST /api/media/sign` (signed URL) or `POST /api/media/ingest` (direct ingest) and record the returned canonical URL.
  - Optionally write an index under `/public/media/index.json` and a local copy under `/public/media/YYYY/MM/DD/<hash>.<ext>` for offline viewing.

### Server API additions
- **POST `/api/media/sign`** (if we prefer clientâ€‘side upload to signed URL)
  - Request: `{ contentType: string, ext?: string, scope?: { desktopId?: string, appId?: string }, metadata?: Record<string,string> }`
  - Response: `{ url: string, r2Key: string, publicUrl?: string }`
  - Implementation: use existing Convex R2 client to `generateUploadUrl` similar to publish flows.

- **POST `/api/media/ingest`** (simpler path for hostâ€‘side fetch/reâ€‘upload)
  - Request: `{ sourceUrl?: string, base64?: string, contentType?: string, filenameHint?: string, scope?: { desktopId?: string, appId?: string }, metadata?: Record<string,string> }`
  - Behavior: If `sourceUrl` is present, server fetches bytes; if `base64` is present, decode to bytes; determine content type and extension with a safe detector; upload to R2 via signed URL; return canonical URL and metadata.
  - Response: `{ ok: true, contentType: string, size: number, r2Key: string, publicUrl: string, sha256: string }`

### Storage layout and metadata
- R2 key proposal: `media/{ownerId}/{desktopId}/{appId}/{YYYY}/{MM}/{DD}/{sha256}.{ext}`. If `desktopId`/`appId` not available, omit those segments.
- Deâ€‘duplication: compute SHAâ€‘256 on bytes; if the hash already exists, skip reâ€‘upload and return the existing URL.
- Public URL: Either via R2â€™s public bucket or a CDN mapping; store and return `publicUrl` for direct use in apps.

### Providerâ€‘specific extraction (initial heuristics)
- **FAL (image/video)**: Responses commonly include arrays of outputs with `url` strings. For each URL:
  - Fetch bytes on the server.
  - Detect content type; upload; substitute URLs in the result body.

- **ElevenLabs (music/audio)**: Route already returns `{ contentType, audioBase64 }` when the provider response is binary.
```36:44:src/app/api/ai/eleven/route.ts
const ct = elRes.headers.get('Content-Type') || '';
if (ct.includes('application/json')) {
  const json = await elRes.json();
  return Response.json(json);
}
const arrayBuffer = await elRes.arrayBuffer();
const base64 = Buffer.from(arrayBuffer).toString('base64');
return Response.json({ ok: true, contentType: ct || 'audio/mpeg', audioBase64: base64 });
```
- When `audioBase64` is present, upload those bytes and replace with a persisted `audioUrl` in the response to the app.

### Desktop/app context for attribution
- To associate media with an app without perâ€‘app code:
  - `templates/webcontainer/app.html` already sets query params `?path=...&name=...&id=...` on the app iframe.
  - Enhance the platform helper `templates/webcontainer/src/ai/index.ts` (not each app) to read `id`/`name` from `location.search` and include `{ appId, appName }` in the `AI_REQUEST` payload. The host bridge can then forward this `scope` to `/api/media/*` for foldering and metadata. This is a oneâ€‘time platform change, not perâ€‘app.

### Indexing and discovery (optional, nice to have)
- Maintain `/public/media/index.json` inside the WebContainer for offline listing.
- Add routes:
  - `GET /api/media/list` â†’ list by `ownerId`, `desktopId`, `appId`, date range, type.
  - `GET /api/media/:id` â†’ serve or redirect to CDN URL.

### Security & privacy
- Do not expose signed PUT URLs to iframes directly unless needed; prefer hostâ€‘side fetch/reâ€‘upload (`/api/media/ingest`) to avoid leaking credentials.
- Validate `sourceUrl` origins when ingesting to prevent SSRF. Enforce size limits and type allowlist.
- Ensure buckets are private unless intentionally public via a CDN domain.

### Edge cases and limitations
- Media generated entirely clientâ€‘side (e.g., canvas export) without going through AI providers will not be autoâ€‘captured unless itâ€™s saved to the VFS by the agent or the platform provides a small helper (e.g., future `@/ai` adds `persistBlob()` that posts a message to the host). This keeps perâ€‘app changes optional.
- Very large videos might need multipart upload; start with singleâ€‘PUT signed URLs and add multipart later if needed.

<!-- Implementation plan moved to docs/setup/files/plan.md -->

### Why this meets the requirement
- Automatic: Apps already call the AI helpers; the platform intercepts provider results and persists media without perâ€‘app code.
- Durable: Assets are uploaded to remote object storage (R2) with canonical URLs.
- Extensible: Provider adapters and fileâ€‘write hooks cover more cases over time.


